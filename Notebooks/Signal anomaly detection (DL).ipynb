{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, BatchNormalization\n",
    "from tensorflow.keras import optimizers, initializers\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.optimizer.set_jit(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shape = (K, N), labels.shape = (1000,)\n",
    "# data: 1000 K time series, each with N timesteps\n",
    "# labels: N labels (0-good or 1-outlier), corresponding to each time series\n",
    "name = \"testCase0\"\n",
    "data = np.load(name+\".npy\")\n",
    "labels = np.load(name+\"_labels.npy\")\n",
    "K = data.shape[0]\n",
    "N = data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Reshape and Oversample the Minority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume `data` is the (K, N) numpy matrix with time series and `labels` is the (N,) label array\n",
    "data = data.reshape(K, N, 1)\n",
    "\n",
    "# Separate majority and minority classes\n",
    "good_data = data[labels == 0]\n",
    "bad_data = data[labels == 1]\n",
    "\n",
    "good_labels = labels[labels == 0]\n",
    "bad_labels = labels[labels == 1]\n",
    "\n",
    "# Oversample the minority class (bad_data)\n",
    "bad_data_oversampled, bad_labels_oversampled = resample(bad_data, bad_labels,\n",
    "                                                        replace=True,  # Allow resampling with replacement\n",
    "                                                        n_samples=len(good_data),  # Match the number of \"good\" data points\n",
    "                                                        random_state=42)\n",
    "\n",
    "# Combine the oversampled data with the majority class data\n",
    "data_oversampled = np.vstack((good_data, bad_data_oversampled))\n",
    "labels_oversampled = np.hstack((good_labels, bad_labels_oversampled))\n",
    "\n",
    "# Shuffle the data to ensure random ordering\n",
    "indices = np.random.permutation(len(labels_oversampled))\n",
    "data_oversampled = data_oversampled[indices]\n",
    "labels_oversampled = labels_oversampled[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Train-Test Split and Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the oversampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_oversampled, labels_oversampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data (fit only on training data to avoid data leakage)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Reshape data to 2D for scaling, then back to original shape\n",
    "X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])\n",
    "X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_reshaped).reshape(X_train.shape)\n",
    "X_test_scaled = scaler.transform(X_test_reshaped).reshape(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Build the LSTM-based Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 500, 128)          66560     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 118,081\n",
      "Trainable params: 118,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a Sequential model with LSTM layers\n",
    "model = Sequential()\n",
    "\n",
    "# Add an LSTM layer\n",
    "model.add(LSTM(128, input_shape=(N, 1), return_sequences=True))  # LSTM for sequence data\n",
    "model.add(LSTM(64, input_shape=(N, 1), return_sequences=False))  # LSTM for sequence data\n",
    "model.add(Dense(32, activation='relu'))  # Fully connected layer with 32 units\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model with binary crossentropy loss and Adam optimizer\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 15:02:52.492405: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1652] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 321s 3s/step - loss: 0.6085 - accuracy: 0.6631 - val_loss: 0.5484 - val_accuracy: 0.7395\n",
      "Epoch 2/50\n",
      "107/107 [==============================] - 365s 3s/step - loss: 0.5554 - accuracy: 0.7183 - val_loss: 0.5783 - val_accuracy: 0.6868\n",
      "Epoch 3/50\n",
      "107/107 [==============================] - 383s 4s/step - loss: 0.5397 - accuracy: 0.7311 - val_loss: 0.6085 - val_accuracy: 0.6961\n",
      "Epoch 4/50\n",
      "107/107 [==============================] - 391s 4s/step - loss: 0.5330 - accuracy: 0.7243 - val_loss: 0.4896 - val_accuracy: 0.7572\n",
      "Epoch 5/50\n",
      "107/107 [==============================] - 390s 4s/step - loss: 0.5001 - accuracy: 0.7506 - val_loss: 0.4946 - val_accuracy: 0.7625\n",
      "Epoch 6/50\n",
      "107/107 [==============================] - 407s 4s/step - loss: 0.4982 - accuracy: 0.7548 - val_loss: 0.4734 - val_accuracy: 0.7625\n",
      "Epoch 7/50\n",
      "107/107 [==============================] - 416s 4s/step - loss: 0.4936 - accuracy: 0.7648 - val_loss: 0.4571 - val_accuracy: 0.7750\n",
      "Epoch 8/50\n",
      "107/107 [==============================] - 382s 4s/step - loss: 0.4722 - accuracy: 0.7738 - val_loss: 0.4901 - val_accuracy: 0.7467\n",
      "Epoch 9/50\n",
      "107/107 [==============================] - 389s 4s/step - loss: 0.4685 - accuracy: 0.7764 - val_loss: 0.4547 - val_accuracy: 0.7921\n",
      "Epoch 10/50\n",
      "107/107 [==============================] - 361s 3s/step - loss: 0.4546 - accuracy: 0.7846 - val_loss: 0.4569 - val_accuracy: 0.7816\n",
      "Epoch 11/50\n",
      "107/107 [==============================] - 368s 3s/step - loss: 0.4507 - accuracy: 0.7870 - val_loss: 0.4444 - val_accuracy: 0.7954\n",
      "Epoch 12/50\n",
      "107/107 [==============================] - 364s 3s/step - loss: 0.4518 - accuracy: 0.7835 - val_loss: 0.4346 - val_accuracy: 0.7941\n",
      "Epoch 13/50\n",
      "107/107 [==============================] - 350s 3s/step - loss: 0.4396 - accuracy: 0.7887 - val_loss: 0.4393 - val_accuracy: 0.8072\n",
      "Epoch 14/50\n",
      "107/107 [==============================] - 353s 3s/step - loss: 0.4375 - accuracy: 0.7914 - val_loss: 0.4296 - val_accuracy: 0.8000\n",
      "Epoch 15/50\n",
      "107/107 [==============================] - 367s 3s/step - loss: 0.4379 - accuracy: 0.7907 - val_loss: 0.4228 - val_accuracy: 0.8132\n",
      "Epoch 16/50\n",
      "107/107 [==============================] - 349s 3s/step - loss: 0.4251 - accuracy: 0.7963 - val_loss: 0.4594 - val_accuracy: 0.7776\n",
      "Epoch 17/50\n",
      "107/107 [==============================] - 341s 3s/step - loss: 0.4189 - accuracy: 0.8012 - val_loss: 0.4199 - val_accuracy: 0.8013\n",
      "Epoch 18/50\n",
      "107/107 [==============================] - 376s 4s/step - loss: 0.4069 - accuracy: 0.8098 - val_loss: 0.3954 - val_accuracy: 0.8276\n",
      "Epoch 19/50\n",
      "107/107 [==============================] - 343s 3s/step - loss: 0.4018 - accuracy: 0.8107 - val_loss: 0.4056 - val_accuracy: 0.8125\n",
      "Epoch 20/50\n",
      "107/107 [==============================] - 384s 4s/step - loss: 0.3911 - accuracy: 0.8142 - val_loss: 0.3983 - val_accuracy: 0.8250\n",
      "Epoch 21/50\n",
      "107/107 [==============================] - 382s 4s/step - loss: 0.3917 - accuracy: 0.8205 - val_loss: 0.4084 - val_accuracy: 0.8059\n",
      "Epoch 22/50\n",
      "107/107 [==============================] - 312s 3s/step - loss: 0.3824 - accuracy: 0.8233 - val_loss: 0.3692 - val_accuracy: 0.8322\n",
      "Epoch 23/50\n",
      "107/107 [==============================] - 330s 3s/step - loss: 0.3602 - accuracy: 0.8368 - val_loss: 0.3637 - val_accuracy: 0.8368\n",
      "Epoch 24/50\n",
      "107/107 [==============================] - 352s 3s/step - loss: 0.3619 - accuracy: 0.8371 - val_loss: 0.3936 - val_accuracy: 0.8237\n",
      "Epoch 25/50\n",
      "107/107 [==============================] - 378s 4s/step - loss: 0.3573 - accuracy: 0.8395 - val_loss: 0.3603 - val_accuracy: 0.8342\n",
      "Epoch 26/50\n",
      "107/107 [==============================] - 361s 3s/step - loss: 0.3384 - accuracy: 0.8523 - val_loss: 0.3371 - val_accuracy: 0.8632\n",
      "Epoch 27/50\n",
      "107/107 [==============================] - 348s 3s/step - loss: 0.3481 - accuracy: 0.8481 - val_loss: 0.3223 - val_accuracy: 0.8625\n",
      "Epoch 28/50\n",
      "107/107 [==============================] - 371s 3s/step - loss: 0.3056 - accuracy: 0.8685 - val_loss: 0.3162 - val_accuracy: 0.8618\n",
      "Epoch 29/50\n",
      "107/107 [==============================] - 413s 4s/step - loss: 0.3146 - accuracy: 0.8678 - val_loss: 0.4031 - val_accuracy: 0.8072\n",
      "Epoch 30/50\n",
      "107/107 [==============================] - 391s 4s/step - loss: 0.3139 - accuracy: 0.8677 - val_loss: 0.2203 - val_accuracy: 0.9066\n",
      "Epoch 31/50\n",
      "107/107 [==============================] - 384s 4s/step - loss: 0.6318 - accuracy: 0.6530 - val_loss: 0.5822 - val_accuracy: 0.6849\n",
      "Epoch 32/50\n",
      "107/107 [==============================] - 392s 4s/step - loss: 0.5542 - accuracy: 0.7086 - val_loss: 0.4637 - val_accuracy: 0.8112\n",
      "Epoch 33/50\n",
      "107/107 [==============================] - 380s 4s/step - loss: 0.5194 - accuracy: 0.7318 - val_loss: 0.2245 - val_accuracy: 0.9250\n",
      "Epoch 34/50\n",
      "107/107 [==============================] - 395s 4s/step - loss: 0.7292 - accuracy: 0.5510 - val_loss: 0.6801 - val_accuracy: 0.5322\n",
      "Epoch 35/50\n",
      "107/107 [==============================] - 381s 4s/step - loss: 0.6402 - accuracy: 0.6522 - val_loss: 0.5844 - val_accuracy: 0.6947\n",
      "Epoch 36/50\n",
      "107/107 [==============================] - 375s 4s/step - loss: 0.6593 - accuracy: 0.6101 - val_loss: 0.5698 - val_accuracy: 0.7368\n",
      "Epoch 37/50\n",
      "107/107 [==============================] - 377s 4s/step - loss: 0.4725 - accuracy: 0.7550 - val_loss: 0.6152 - val_accuracy: 0.6901\n",
      "Epoch 38/50\n",
      "107/107 [==============================] - 368s 3s/step - loss: 0.6385 - accuracy: 0.6270 - val_loss: 0.5584 - val_accuracy: 0.7178\n",
      "Epoch 39/50\n",
      "107/107 [==============================] - 373s 3s/step - loss: 0.5692 - accuracy: 0.7076 - val_loss: 0.5582 - val_accuracy: 0.7480\n",
      "Epoch 40/50\n",
      "107/107 [==============================] - 347s 3s/step - loss: 0.4571 - accuracy: 0.7907 - val_loss: 0.5080 - val_accuracy: 0.7816\n",
      "119/119 [==============================] - 262s 2s/step - loss: 0.2326 - accuracy: 0.9061\n",
      "Test Accuracy: 0.9061\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=128, validation_split=0.1, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss over epochs\n",
    "def plot_history(history, plus_accuracy = True):\n",
    "    # Get the values from the history object\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']    \n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    \n",
    "    # Plot Loss\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Subplot 1: Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Subplot 2: Accuracy\n",
    "    if plus_accuracy:\n",
    "        accuracy = history.history['accuracy']\n",
    "        val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "        plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "    # Display the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the plot_history function to visualize the training process\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"val_testCase0\"\n",
    "val_data = np.load(name+\".npy\")\n",
    "val_labels = np.load(name+\"_labels.npy\")\n",
    "val_K = val_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = val_data.reshape(val_K, N, 1)\n",
    "X_val_reshaped = val_data.reshape(-1, val_data.shape[-1])\n",
    "X_val_scaled = scaler.transform(X_val_reshaped).reshape(val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 67s 2s/step - loss: 0.2678 - accuracy: 0.8880\n",
      "Validation Accuracy: 0.8880\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f7aa81aae60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f7aa81aae60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Validation AUROC: 0.8945\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy = model.evaluate(X_val_scaled, val_labels)\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Predict probabilities on the validation set\n",
    "y_val_pred_probs = model.predict(X_val_scaled)\n",
    "\n",
    "# Compute AUROC\n",
    "val_auroc = roc_auc_score(val_labels, y_val_pred_probs)\n",
    "print(f'Validation AUROC: {val_auroc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised RNN (autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 500, 1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "KG = data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test both scaling and normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_auto = StandardScaler()\n",
    "data_scaled = scaler_auto.fit_transform(data.reshape(-1, 1)).reshape(KG, N, 1)\n",
    "data_norm = (data - data.min()) / (data.max() - data.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for NaN and inf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(data_scaled).sum())  # Check for NaN values\n",
    "print(np.isinf(data_scaled).sum())  # Check for infinite values\n",
    "print(np.isnan(data_norm).sum())  # Check for NaN values\n",
    "print(np.isinf(data_norm).sum())  # Check for infinite values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check \n",
    "- Adam and RMSprop\n",
    "- learning_rate=1e-4, learning_rate=1e-5\n",
    "- clipnorm=1.0, clipvalue=1.0\n",
    "- different batch sizes\n",
    "- batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Autoencoder model (LSTM-based)\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(N, 1), return_sequences=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(RepeatVector(N))  # Repeat vector to match the input shape for decoding\n",
    "model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))  # Output layer with the same time steps\n",
    "\n",
    "# Compile the model\n",
    "# optimizers.Adam\n",
    "model.compile(optimizer=optimizers.RMSprop(learning_rate=1e-5, clipnorm=1.0), loss='mse')\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "71/71 [==============================] - 62s 847ms/step - loss: 0.2340 - val_loss: 0.2802\n",
      "Epoch 2/50\n",
      "71/71 [==============================] - 58s 812ms/step - loss: 0.2109 - val_loss: 0.2704\n",
      "Epoch 3/50\n",
      "71/71 [==============================] - 56s 789ms/step - loss: 0.1900 - val_loss: 0.2585\n",
      "Epoch 4/50\n",
      "71/71 [==============================] - 59s 832ms/step - loss: 0.1708 - val_loss: 0.2442\n",
      "Epoch 5/50\n",
      "71/71 [==============================] - 56s 791ms/step - loss: 0.1529 - val_loss: 0.2257\n",
      "Epoch 6/50\n",
      "71/71 [==============================] - 60s 850ms/step - loss: 0.1369 - val_loss: 0.2021\n",
      "Epoch 7/50\n",
      "71/71 [==============================] - 63s 887ms/step - loss: 0.1220 - val_loss: 0.1726\n",
      "Epoch 8/50\n",
      "71/71 [==============================] - 58s 813ms/step - loss: 0.1094 - val_loss: 0.1396\n",
      "Epoch 9/50\n",
      "71/71 [==============================] - 57s 797ms/step - loss: 0.0992 - val_loss: 0.1100\n",
      "Epoch 10/50\n",
      "71/71 [==============================] - 59s 830ms/step - loss: 0.0911 - val_loss: 0.0904\n",
      "Epoch 11/50\n",
      "71/71 [==============================] - 59s 832ms/step - loss: 0.0844 - val_loss: 0.0810\n",
      "Epoch 12/50\n",
      "71/71 [==============================] - 61s 859ms/step - loss: 0.0787 - val_loss: 0.0746\n",
      "Epoch 13/50\n",
      "71/71 [==============================] - 57s 798ms/step - loss: 0.0726 - val_loss: 0.0693\n",
      "Epoch 14/50\n",
      "71/71 [==============================] - 58s 823ms/step - loss: 0.0669 - val_loss: 0.0635\n",
      "Epoch 15/50\n",
      "71/71 [==============================] - 50s 706ms/step - loss: 0.0610 - val_loss: 0.0581\n",
      "Epoch 16/50\n",
      "71/71 [==============================] - 58s 823ms/step - loss: 0.0549 - val_loss: 0.0523\n",
      "Epoch 17/50\n",
      "71/71 [==============================] - 55s 774ms/step - loss: 0.0487 - val_loss: 0.0464\n",
      "Epoch 18/50\n",
      "71/71 [==============================] - 55s 780ms/step - loss: 0.0426 - val_loss: 0.0406\n",
      "Epoch 19/50\n",
      "71/71 [==============================] - 50s 710ms/step - loss: 0.0369 - val_loss: 0.0354\n",
      "Epoch 20/50\n",
      "71/71 [==============================] - 49s 691ms/step - loss: 0.0320 - val_loss: 0.0311\n",
      "Epoch 21/50\n",
      "71/71 [==============================] - 51s 718ms/step - loss: 0.0287 - val_loss: 0.0281\n",
      "Epoch 22/50\n",
      "71/71 [==============================] - 54s 765ms/step - loss: 0.0269 - val_loss: 0.0267\n",
      "Epoch 23/50\n",
      "71/71 [==============================] - 57s 799ms/step - loss: 0.0262 - val_loss: 0.0260\n",
      "Epoch 24/50\n",
      "71/71 [==============================] - 59s 828ms/step - loss: 0.0260 - val_loss: 0.0257\n",
      "Epoch 25/50\n",
      "71/71 [==============================] - 56s 786ms/step - loss: 0.0259 - val_loss: 0.0256\n",
      "Epoch 26/50\n",
      "71/71 [==============================] - 62s 875ms/step - loss: 0.0258 - val_loss: 0.0255\n",
      "Epoch 27/50\n",
      "71/71 [==============================] - 60s 841ms/step - loss: 0.0257 - val_loss: 0.0254\n",
      "Epoch 28/50\n",
      "71/71 [==============================] - 61s 858ms/step - loss: 0.0257 - val_loss: 0.0254\n",
      "Epoch 29/50\n",
      "71/71 [==============================] - 63s 895ms/step - loss: 0.0256 - val_loss: 0.0254\n",
      "Epoch 30/50\n",
      "71/71 [==============================] - 60s 841ms/step - loss: 0.0256 - val_loss: 0.0253\n",
      "Epoch 31/50\n",
      "71/71 [==============================] - 59s 829ms/step - loss: 0.0256 - val_loss: 0.0253\n",
      "Epoch 32/50\n",
      "71/71 [==============================] - 55s 781ms/step - loss: 0.0256 - val_loss: 0.0253\n",
      "Epoch 33/50\n",
      "71/71 [==============================] - 60s 852ms/step - loss: 0.0255 - val_loss: 0.0253\n",
      "Epoch 34/50\n",
      "71/71 [==============================] - 54s 764ms/step - loss: 0.0255 - val_loss: 0.0252\n",
      "Epoch 35/50\n",
      "71/71 [==============================] - 67s 954ms/step - loss: 0.0255 - val_loss: 0.0252\n",
      "Epoch 36/50\n",
      "71/71 [==============================] - 59s 826ms/step - loss: 0.0255 - val_loss: 0.0252\n",
      "Epoch 37/50\n",
      "71/71 [==============================] - 60s 843ms/step - loss: 0.0255 - val_loss: 0.0252\n",
      "Epoch 38/50\n",
      "71/71 [==============================] - 57s 811ms/step - loss: 0.0255 - val_loss: 0.0252\n",
      "Epoch 39/50\n",
      "71/71 [==============================] - 60s 849ms/step - loss: 0.0254 - val_loss: 0.0252\n",
      "Epoch 40/50\n",
      "71/71 [==============================] - 55s 779ms/step - loss: 0.0254 - val_loss: 0.0252\n",
      "Epoch 41/50\n",
      "71/71 [==============================] - 54s 756ms/step - loss: 0.0254 - val_loss: 0.0252\n",
      "Epoch 42/50\n",
      "71/71 [==============================] - 57s 798ms/step - loss: 0.0254 - val_loss: 0.0251\n",
      "Epoch 43/50\n",
      "71/71 [==============================] - 54s 753ms/step - loss: 0.0254 - val_loss: 0.0252\n",
      "Epoch 44/50\n",
      "71/71 [==============================] - 54s 756ms/step - loss: 0.0254 - val_loss: 0.0251\n",
      "Epoch 45/50\n",
      "71/71 [==============================] - 57s 807ms/step - loss: 0.0254 - val_loss: 0.0251\n",
      "Epoch 46/50\n",
      "71/71 [==============================] - 57s 800ms/step - loss: 0.0254 - val_loss: 0.0251\n",
      "Epoch 47/50\n",
      "71/71 [==============================] - 54s 761ms/step - loss: 0.0254 - val_loss: 0.0251\n",
      "Epoch 48/50\n",
      "71/71 [==============================] - 59s 834ms/step - loss: 0.0254 - val_loss: 0.0251\n",
      "Epoch 49/50\n",
      "71/71 [==============================] - 55s 770ms/step - loss: 0.0254 - val_loss: 0.0251\n",
      "Epoch 50/50\n",
      "71/71 [==============================] - 50s 703ms/step - loss: 0.0254 - val_loss: 0.0251\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model on the majority class (you can identify majority class data via labels or all data assuming unsupervised setting)\n",
    "history = model.fit(data_norm, data_norm, \n",
    "                    epochs=50, batch_size=128, validation_split=0.1, \n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the reconstructed data\n",
    "def get_anomalies(data, percentile):\n",
    "    reconstructed_data = model.predict(data)\n",
    "\n",
    "    # Calculate the reconstruction error\n",
    "    reconstruction_error = np.mean(np.power(data - reconstructed_data, 2), axis=1)\n",
    "\n",
    "    # Set a threshold for anomaly detection based on the reconstruction error\n",
    "    threshold = np.percentile(reconstruction_error, percentile)  # Example: top 5% highest errors are anomalies\n",
    "\n",
    "    # Classify time series as anomalies if their reconstruction error exceeds the threshold\n",
    "    # anomalies is a boolean array, where True indicates a likely \"bad\" time series\n",
    "    anomalies = reconstruction_error > threshold    \n",
    "    prediction_labels = np.where(anomalies, 0, 1)\n",
    "    \n",
    "    return prediction_labels, reconstruction_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9080\n",
      "Validation AUROC: 0.5812\n"
     ]
    }
   ],
   "source": [
    "X_val_scaled = scaler_auto.transform(val_data.reshape(-1, val_data.shape[-1])).reshape(val_data.shape)\n",
    "X_val_norm = (val_data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "y_val_pred, y_val_pred_probs = get_anomalies(X_val_norm, 95)\n",
    "val_accuracy = accuracy_score(val_labels, y_val_pred)    \n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "val_auroc = roc_auc_score(val_labels, y_val_pred_probs)\n",
    "print(f'Validation AUROC: {val_auroc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short window classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(dataset, history_size, label:int):\n",
    "    data = []\n",
    "    labels = []\n",
    "    start_index = history_size\n",
    "    end_index = len(dataset[0])    \n",
    "    for c in range(len(dataset)):\n",
    "        for i in range(start_index, end_index):\n",
    "            indices = range(i-history_size, i)\n",
    "            # Reshape data from (history_size,) to (history_size, 1)\n",
    "            data.append(np.reshape(dataset[c][indices], (history_size, 1)))\n",
    "            labels.append(label)\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_history = 200 #hours\n",
    "good_data_windows, good_labels_windows = sliding_window(good_data, past_history, 0)\n",
    "bad_data_windows, bad_labels_windows = sliding_window(bad_data, past_history, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample the minority class (bad_data)\n",
    "bad_data_windows_oversampled, bad_labels_windows_oversampled = resample(bad_data_windows, bad_labels_windows,\n",
    "                                                        replace=True,  # Allow resampling with replacement\n",
    "                                                        n_samples=len(good_data_windows),  # Match the number of \"good\" data points\n",
    "                                                        random_state=42)\n",
    "\n",
    "# Combine the oversampled data with the majority class data\n",
    "data_windows_oversampled = np.vstack((good_data_windows, bad_data_windows_oversampled))\n",
    "labels_windows_oversampled = np.hstack((good_labels_windows, bad_labels_windows_oversampled))\n",
    "\n",
    "# Shuffle the data to ensure random ordering\n",
    "indices = np.random.permutation(len(labels_windows_oversampled))\n",
    "data_windows_oversampled = data_windows_oversampled[indices]\n",
    "labels_windows_oversampled = labels_windows_oversampled[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5700000, 200, 1)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_windows_oversampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the oversampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_windows_oversampled, labels_windows_oversampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data (fit only on training data to avoid data leakage)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Reshape data to 2D for scaling, then back to original shape\n",
    "X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])\n",
    "X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_reshaped).reshape(X_train.shape)\n",
    "X_test_scaled = scaler.transform(X_test_reshaped).reshape(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_55 (LSTM)               (None, 200, 128)          66560     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 200, 32)           4128      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 200, 1)            33        \n",
      "=================================================================\n",
      "Total params: 70,721\n",
      "Trainable params: 70,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a Sequential model with LSTM layers\n",
    "model = Sequential()\n",
    "\n",
    "# Add an LSTM layer\n",
    "model.add(LSTM(128, input_shape=(past_history, 1), return_sequences=True))  # LSTM for sequence data\n",
    "model.add(Dense(32, activation='relu'))  # Fully connected layer with 32 units\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model with binary crossentropy loss and Adam optimizer\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32063/32063 [==============================] - 19874s 620ms/step - loss: 0.4128 - accuracy: 0.7946 - val_loss: 0.3345 - val_accuracy: 0.8400\n",
      "Epoch 2/50\n",
      "32063/32063 [==============================] - 22003s 686ms/step - loss: 0.2895 - accuracy: 0.8623 - val_loss: 0.2616 - val_accuracy: 0.8757\n",
      "Epoch 3/50\n",
      "32063/32063 [==============================] - 22510s 702ms/step - loss: 0.2342 - accuracy: 0.8882 - val_loss: 0.2171 - val_accuracy: 0.8958\n",
      "Epoch 4/50\n",
      "32063/32063 [==============================] - 43702s 1s/step - loss: 0.2034 - accuracy: 0.9018 - val_loss: 0.1890 - val_accuracy: 0.9081\n",
      "Epoch 5/50\n",
      "  898/32063 [..............................] - ETA: 100:11:13 - loss: 0.1912 - accuracy: 0.9071"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32063/32063 [==============================] - 322741s 10s/step - loss: 0.1839 - accuracy: 0.9105 - val_loss: 0.1756 - val_accuracy: 0.9142\n",
      "Epoch 6/50\n",
      "32063/32063 [==============================] - 21323s 665ms/step - loss: 0.1706 - accuracy: 0.9164 - val_loss: 0.1637 - val_accuracy: 0.9195\n",
      "Epoch 7/50\n",
      "32063/32063 [==============================] - 22334s 697ms/step - loss: 0.1607 - accuracy: 0.9209 - val_loss: 0.1520 - val_accuracy: 0.9247\n",
      "Epoch 8/50\n",
      "32063/32063 [==============================] - 22878s 714ms/step - loss: 0.1525 - accuracy: 0.9247 - val_loss: 0.1577 - val_accuracy: 0.9235\n",
      "Epoch 9/50\n",
      "32063/32063 [==============================] - 27881s 870ms/step - loss: 0.1452 - accuracy: 0.9280 - val_loss: 0.1401 - val_accuracy: 0.9303\n",
      "Epoch 10/50\n",
      "32063/32063 [==============================] - 25271s 788ms/step - loss: 0.1396 - accuracy: 0.9306 - val_loss: 0.1392 - val_accuracy: 0.9308\n",
      "Epoch 11/50\n",
      "32063/32063 [==============================] - 23380s 729ms/step - loss: 0.1348 - accuracy: 0.9328 - val_loss: 0.1289 - val_accuracy: 0.9354\n",
      "Epoch 12/50\n",
      "32063/32063 [==============================] - 24988s 779ms/step - loss: 0.1300 - accuracy: 0.9350 - val_loss: 0.1279 - val_accuracy: 0.9359\n",
      "Epoch 13/50\n",
      "32063/32063 [==============================] - 23109s 721ms/step - loss: 0.1262 - accuracy: 0.9367 - val_loss: 0.1200 - val_accuracy: 0.9393\n",
      "Epoch 14/50\n",
      "32063/32063 [==============================] - 25084s 782ms/step - loss: 0.1227 - accuracy: 0.9383 - val_loss: 0.1187 - val_accuracy: 0.9399\n",
      "Epoch 15/50\n",
      "32063/32063 [==============================] - 23933s 746ms/step - loss: 0.1192 - accuracy: 0.9399 - val_loss: 0.1178 - val_accuracy: 0.9405\n",
      "Epoch 16/50\n",
      "32063/32063 [==============================] - 33616s 1s/step - loss: 0.1164 - accuracy: 0.9412 - val_loss: 0.1116 - val_accuracy: 0.9431\n",
      "Epoch 17/50\n",
      "32063/32063 [==============================] - 25278s 788ms/step - loss: 0.1137 - accuracy: 0.9424 - val_loss: 0.1155 - val_accuracy: 0.9420\n",
      "Epoch 18/50\n",
      "32063/32063 [==============================] - 27213s 849ms/step - loss: 0.1116 - accuracy: 0.9434 - val_loss: 0.1204 - val_accuracy: 0.9403\n",
      "Epoch 19/50\n",
      "32063/32063 [==============================] - 33445s 1s/step - loss: 0.1103 - accuracy: 0.9441 - val_loss: 0.1093 - val_accuracy: 0.9446\n",
      "Epoch 20/50\n",
      "32063/32063 [==============================] - 77888s 2s/step - loss: 0.5108 - accuracy: 0.7277 - val_loss: 0.5723 - val_accuracy: 0.6899\n",
      "Epoch 21/50\n",
      "32063/32063 [==============================] - 32853s 1s/step - loss: 0.5999 - accuracy: 0.6644 - val_loss: 0.6448 - val_accuracy: 0.6217\n",
      "Epoch 22/50\n",
      "32063/32063 [==============================] - 23913s 746ms/step - loss: 0.6217 - accuracy: 0.6438 - val_loss: 0.6229 - val_accuracy: 0.6422\n",
      "Epoch 23/50\n",
      "32063/32063 [==============================] - 25050s 781ms/step - loss: 0.6084 - accuracy: 0.6579 - val_loss: 0.6032 - val_accuracy: 0.6572\n",
      "Epoch 24/50\n",
      "32063/32063 [==============================] - 23544s 734ms/step - loss: 0.6026 - accuracy: 0.6623 - val_loss: 0.6104 - val_accuracy: 0.6632\n",
      "Epoch 25/50\n",
      "32063/32063 [==============================] - 24005s 749ms/step - loss: 0.6110 - accuracy: 0.6554 - val_loss: 0.5956 - val_accuracy: 0.6713\n",
      "Epoch 26/50\n",
      "32063/32063 [==============================] - 21333s 665ms/step - loss: 0.5975 - accuracy: 0.6653 - val_loss: 0.5938 - val_accuracy: 0.6676\n",
      "Epoch 27/50\n",
      "32063/32063 [==============================] - 21753s 678ms/step - loss: 0.5687 - accuracy: 0.6868 - val_loss: 0.5067 - val_accuracy: 0.7404\n",
      "Epoch 28/50\n",
      "32063/32063 [==============================] - 75821s 2s/step - loss: 0.4732 - accuracy: 0.7607 - val_loss: 0.4217 - val_accuracy: 0.7911\n",
      "Epoch 29/50\n",
      "32063/32063 [==============================] - 21437s 669ms/step - loss: 0.4509 - accuracy: 0.7704 - val_loss: 0.5568 - val_accuracy: 0.7026\n",
      "35625/35625 [==============================] - 2645s 74ms/step - loss: 0.1093 - accuracy: 0.9446\n",
      "Test Accuracy: 0.9446\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=128, validation_split=0.1, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
